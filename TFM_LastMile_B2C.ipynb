{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/egarmir/TFM_LastMile_Pulse/blob/main/TFM_LastMile_B2C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIInnU3_hsIf"
      },
      "source": [
        "### **Carga del dataset desde HuggingFace**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SRCVK3h_McQ"
      },
      "source": [
        "El subdataset LaDe-D (Last-mile Delivery) proporciona información espacio-temporal detallada de entregas de última milla, lo que permite analizar la trazabilidad completa del pedido desde la aceptación por parte del transportista hasta la entrega final al cliente, identificando patrones de retraso y cuellos de botella a nivel urbano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axvdoHRm_O4l"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RmOtx4e_Q5m"
      },
      "outputs": [],
      "source": [
        "#En LaDe, los CSV NO están en la raíz directa del repo accesible por load_dataset como archivos sueltos, porque el dataset usa un script de carga interno.\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"cainiao-ai/LaDe\",\n",
        "    data_dir=\"delivery\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHZSc8_8_att"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = dataset[\"train\"].to_pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y73883v5_bXH"
      },
      "outputs": [],
      "source": [
        "# Nos quedamos solo con Shanghai y Chongqing\n",
        "cities_selected = [\"Shanghai\", \"Chongqing\"]\n",
        "df = df[df[\"city\"].isin(cities_selected)]\n",
        "\n",
        "df[\"city\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgFcGzkHIjKy"
      },
      "outputs": [],
      "source": [
        "df = df.reset_index(drop=True)\n",
        "df[\"city\"] = df[\"city\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TswdbMgJ_fEi"
      },
      "source": [
        "### **Comprensión del Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cshneMAw_eBR"
      },
      "outputs": [],
      "source": [
        "# Número de filas y columnas\n",
        "print(\"Dimensiones del dataset:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LIp_hEa_jv9"
      },
      "outputs": [],
      "source": [
        "# Infromación general del dataset\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeOqq8Ql_lqW"
      },
      "outputs": [],
      "source": [
        "# Primer vistazo de las primeras filas\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25MVS34IQ2iO"
      },
      "source": [
        "### **Observaciones Iniciales**:\n",
        "\n",
        "*Variables categóricas*\n",
        "*  City: ciudad donde ocurre el envío - nominal\n",
        "\n",
        "*Variables categóricas codificadas como numéricas*: son identificadores sin significado matemático\n",
        "* region_id\n",
        "* courier_id\n",
        "* aoi_id\n",
        "* aoi_type\n",
        "\n",
        "*Varibles temporales a transformar:*\n",
        "* accept_time -> pasar a datetime\n",
        "* accept_gps_time-> pasar a datetime\n",
        "* delivery time -> pasar a datetime\n",
        "* delivery_gps_time -> pasar a datetime\n",
        "\n",
        "*Variables que aportan poca información:*\n",
        "* order_id -> se conserva solo como identificador\n",
        "\n",
        "*Información duplicada:*\n",
        "* ds -> deriva de delivery_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47OAk6dC_q-g"
      },
      "outputs": [],
      "source": [
        "#Convertir columnas a datetime\n",
        "\n",
        "default_year = '2022'\n",
        "\n",
        "def parse_datetime(col):\n",
        "    return pd.to_datetime(default_year + '-' + col.astype(str),\n",
        "                          format='%Y-%m-%d %H:%M:%S',\n",
        "                          errors='coerce')\n",
        "\n",
        "df['accept_time'] = parse_datetime(df['accept_time'])\n",
        "df['delivery_time'] = parse_datetime(df['delivery_time'])\n",
        "df['accept_gps_time'] = parse_datetime(df['accept_gps_time'])\n",
        "df['delivery_gps_time'] = parse_datetime(df['delivery_gps_time'])\n",
        "\n",
        "df['ds'] = pd.to_datetime(\n",
        "    default_year + df['ds'].astype(str).str.zfill(4),\n",
        "    format='%Y%m%d',\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfjf3DT7hrO8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Estadísticos clave para variables numéricas\n",
        "df.describe(include=np.number)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMwmdVjkmC_H"
      },
      "source": [
        "**Observaciones en Variables Numéricas:**\n",
        "\n",
        "* Order_id -> identificador sin valor análitico\n",
        "\n",
        "  Mínimo: 0 posible valor inválido -> pedido no identificado\n",
        "  \n",
        "* courier_id -> identificador técnico\n",
        "\n",
        "  Mínimo: 0 posible valor inválido -> courier no identificados\n",
        "\n",
        "* aoid_ id\n",
        "\n",
        "  Mínimo: 0 -> probablemnte indica sin AOI asignado -> ver cuántos registros supone para decidir cómo tratarlo\n",
        "\n",
        "* region_id\n",
        "\n",
        "  Rango = 1–166 → número finito de regiones.\n",
        "\n",
        "  Media ≈ 74 → no interpretable (variable categórica).\n",
        "\n",
        "\n",
        "* lng\n",
        "\n",
        "  Rango ≈ 102.08–121.95 → válido para longitudes en China.\n",
        "\n",
        "  Media ≈ 115.7\n",
        "\n",
        "* lat\n",
        "\n",
        "  Rango ≈ 26.7–39.9 → válido para latitudes en China.\n",
        "\n",
        "  Media ≈ 30.6\n",
        "\n",
        "* accept_gps_lng ->\n",
        "\n",
        "  Rango ≈ 105.6 - 121.86 → válido.\n",
        "\n",
        "  Muy similar a lng → consistencia espacial.\n",
        "\n",
        "* accept_gps_lat\n",
        "\n",
        "  Rango ≈ 29.0 - 31.4 → válido.\n",
        "\n",
        "  Desviación pequeña → precisión razonable.\n",
        "\n",
        "* delivery_gps_lang\n",
        "\n",
        "  Mínimo ≈ -0.00009 → valor inválido.\n",
        "\n",
        "  Resto del rango consistente con el área geográfica.\n",
        "\n",
        "* delivery_gps_lat\n",
        "\n",
        "   Mínimo: -0,00009 -> valor inválido\n",
        "\n",
        "* aoi_type\n",
        "\n",
        "  Mínimo: 0 -> sospechoso de ser inválido\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l4VOxqJwqf-"
      },
      "outputs": [],
      "source": [
        "time_cols = ['accept_time', 'accept_gps_time', 'delivery_time', 'delivery_gps_time', 'ds']\n",
        "\n",
        "# Contar nulos por columna\n",
        "nulos = df[time_cols].isna().sum()\n",
        "print(\"Valores nulos por columna:\\n\", nulos)\n",
        "\n",
        "# Rango mínimo y máximo por columna\n",
        "rango = df[time_cols].agg(['min','max'])\n",
        "print(\"Rango temporal por columna:\\n\", rango)\n",
        "\n",
        "# Registros sin sentido: aceptación después de entrega\n",
        "invalid_order = df[\n",
        "    (df['accept_time'] > df['delivery_time']) |\n",
        "    (df['accept_gps_time'] > df['delivery_gps_time'])\n",
        "]\n",
        "\n",
        "print(f\"Número de registros con orden temporal inválido: {len(invalid_order)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZE-vUOBy0BP"
      },
      "source": [
        "**Análisis Descriptivo de Variables Temporales**\n",
        "\n",
        "accept_time\n",
        "\n",
        "* Valores nulos = 0 → todos los pedidos tienen hora de aceptación registrada.\n",
        "\n",
        "* Rango = 2022-05-01 06:11:00 → 2022-12-08 12:10:00 → coherente con el periodo del dataset.\n",
        "\n",
        "accept_gps_time\n",
        "\n",
        "* Valores nulos = 0 → todas las coordenadas GPS de aceptación registradas.\n",
        "\n",
        "* Rango = 2022-05-01 06:11:00 → 2022-12-08 12:10:00 → consistente con accept_time.\n",
        "\n",
        "delivery_time\n",
        "\n",
        "* Valores nulos = 0 → todas las entregas tienen hora registrada.\n",
        "\n",
        "* Rango = 2022-01-11 19:20:00 → 2022-12-31 21:03:00\n",
        "\n",
        "delivery_gps_time\n",
        "\n",
        "* Valores nulos = 0\n",
        "\n",
        "* Rango = 2022-01-11 19:20:00 → 2022-12-31 21:03:00 → coherente con delivery_time.\n",
        "\n",
        "ds -> se eliminará, misma infromación que delivery_time\n",
        "\n",
        "\n",
        "Registros con orden temporal inválido: 3 → extremadamente bajo\n",
        "\n",
        "*Interpretación:* solo unos pocos registros tienen aceptación posterior a la entrega o GPS fuera de secuencia. Se eliminarán"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlJDUPOYARfa"
      },
      "source": [
        "### **Exploración y Calidad del Dato**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8TMIh7XAO-a"
      },
      "outputs": [],
      "source": [
        "(df.isnull().sum() / len(df) * 100).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWIDHUOnAt0U"
      },
      "outputs": [],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique(dropna=False)"
      ],
      "metadata": {
        "id": "Ef3HtLGpRInM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1lNx0wOAzIk"
      },
      "outputs": [],
      "source": [
        "df['delivery_duration_min'] = (\n",
        "    df['delivery_time'] - df['accept_time']\n",
        ").dt.total_seconds() / 60\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aTXbXKw9Ytg"
      },
      "source": [
        "**Observaciones**\n",
        "\n",
        "En última milla B2C, la métrica operativa más relevante no es solo si hay retraso, sino el tiempo real necesario para completar una entrega una vez que el pedido ha sido aceptado por el courier, por ello se crea *\"delivery_duration_min\"*.\n",
        "Esta constituye la variable objetivo principal (target) del proyecto:\n",
        "\n",
        "Esta nueva variable será posteriormente discretizada para definir niveles de riesgo de entrega (bajo, medio y alto) en el modelo de clasificación.\n",
        "\n",
        "Dentro del segmento de alto riesgo, se utilizará como variable continua para predecir el retraso esperado (en minutos) mediante un modelo de regresión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLGA50LRMMt0"
      },
      "source": [
        "#### Tratamiento de inconsistencias temporales y valores no plausibles"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conteo de valores 0 en columnas críticas de identificación\n",
        "id_checks = {\n",
        "    \"Order ID = 0\": (df['order_id'] == 0).sum(),\n",
        "    \"Courier ID = 0\": (df['courier_id'] == 0).sum(),\n",
        "    \"AOI ID = 0\": (df['aoi_id'] == 0).sum(),\n",
        "    \"AOI Type = 0\": (df['aoi_type'] == 0).sum()\n",
        "}\n",
        "\n",
        "for k, v in id_checks.items():\n",
        "    print(f\"{k}: {v} registros ({(v/len(df)*100):.4f}%)\")"
      ],
      "metadata": {
        "id": "qP8BNNz8RoSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtro de identificadores y tipos de área\n",
        "df_saneado= df[\n",
        "    (df['order_id'] != 0) &\n",
        "    (df['courier_id'] != 0) &\n",
        "    (df['aoi_id'] != 0) &\n",
        "    (df['aoi_type'] != 0)\n",
        "].copy()\n",
        "\n",
        "print(f\"Reducción total: {len(df) - len(df_saneado)} registros eliminados.\")\n",
        "print(f\"Dataset final para modelado: {len(df_saneado)} registros.\")"
      ],
      "metadata": {
        "id": "NIKtSxA9SB4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ_i6e7gL09q"
      },
      "outputs": [],
      "source": [
        "# Exploración de la nueva variable delivery_duration\n",
        "print(f\"Valores negativos: {(df_saneado['delivery_duration_min'] < 0).sum()}\")\n",
        "\n",
        "print(df_saneado['delivery_duration_min'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgIG_MPn_j8Q"
      },
      "source": [
        "Se realiza una limpieza de valores extremos en *delivery_duration_min* con el objetivo de eliminar observaciones no plausibles desde el punto de vista operativo y reducir la distorsión estadística."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informe de calidad sobre datos brutos\n",
        "print(\"Diagnóstico de inconsistencias en datos brutos:\")\n",
        "inconsistencias = {\n",
        "    \"Duración < 2 min\": (df_saneado['delivery_duration_min'] < 2).sum(),\n",
        "    \"Duración > 480 min\": (df_saneado['delivery_duration_min'] > 480).sum(),\n",
        "}\n",
        "\n",
        "for k, v in inconsistencias.items():\n",
        "    print(f\"{k}: {v} registros\")"
      ],
      "metadata": {
        "id": "DfuOw-XyQaZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos límites lógicos\n",
        "lower_limit = 2  # Un pedido de menos de 2 min suele ser un error de click\n",
        "upper_limit = 480 #establecemos lim superior\n",
        "\n",
        "df_final = df_saneado[\n",
        "    (df['delivery_duration_min'] >= lower_limit) &\n",
        "    (df['delivery_duration_min'] <= upper_limit)\n",
        "].copy()\n",
        "\n",
        "print(f\"Registros originales: {len(df)}\")\n",
        "print(f\"Registros tras limpieza: {len(df_final)}\")"
      ],
      "metadata": {
        "id": "h44K6YXWQmA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNMV5deyMaKF"
      },
      "outputs": [],
      "source": [
        "df_final.shape\n",
        "df_final.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_avZNrP15HO"
      },
      "source": [
        "### **Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ZmDh_BBuEm"
      },
      "source": [
        "En esta sección se generan nuevas variables explicativas a partir de la información original con el objetivo de capturar patrones temporales, espaciales y operativos que influyen en el riesgo de retraso en la última milla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGGXAG_p-Cr1"
      },
      "source": [
        "#### Variable Objetivo\n",
        "\n",
        "Se define un umbral de entrega a tiempo de 90 minutos, que actúa como referencia para clasificar el riesgo y cuantificar el retraso. A partir de este umbral se crean dos variables objetivo:\n",
        "\n",
        "* on_time_delivery: variable binaria para el modelo de clasificación, donde:\n",
        "\n",
        "  1 indica entrega dentro del tiempo esperado.\n",
        "\n",
        "  0 indica entrega con retraso.\n",
        "\n",
        "* delivery_delay_min: variable continua -> mide el retraso en minutos cuando se supera el umbral definido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYkJOpmM98DG"
      },
      "outputs": [],
      "source": [
        "on_time_threshold = 90\n",
        "\n",
        "# Riesgo 1 cuando el tiempo es mayor a 90\n",
        "df_final['target_risk_delay'] = (df_final['delivery_duration_min'] > on_time_threshold).astype(int)\n",
        "\n",
        "# El retraso son los minutos que están por encima de 90\n",
        "df_final['target_delay_min'] = (\n",
        "    df_final['delivery_duration_min'] - on_time_threshold\n",
        ").clip(lower=0)\n",
        "\n",
        "print(\"Distribución de Riesgo (1 = Retraso, 0 = A tiempo):\")\n",
        "print(df_final['target_risk_delay'].value_counts(normalize=True) * 100)\n",
        "\n",
        "print(\"\\nEstadísticos de los que SÍ tienen retraso:\")\n",
        "display(df_final[df_final['target_risk_delay'] == 1]['target_delay_min'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Indicadores de rendimeinto histórico\n",
        "\n",
        "Una vez definidas las variables objetivo, se procedió a extraer el perfil de comportamiento histórico de cada repartidor, transformando el identificador courier_id en un predictor de rendimiento"
      ],
      "metadata": {
        "id": "V3EV2JsyEPsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Media histórica de retraso por courier\n",
        "df_final['courier_mean_delay'] = (\n",
        "    df_final.groupby('courier_id')['target_delay_min']\n",
        "    .transform('mean')\n",
        ")\n",
        "\n",
        "#Volumen historico del courier\n",
        "df_final['courier_volume'] = (\n",
        "    df_final.groupby('courier_id')['target_delay_min']\n",
        "    .transform('count')\n",
        ")\n",
        "\n",
        "#Tasa de cumplimiento del SLA\n",
        "df_final['courier_sla_rate'] = (\n",
        "    df_final.groupby('courier_id')['target_risk_delay']\n",
        "    .transform('mean')\n",
        ")"
      ],
      "metadata": {
        "id": "tx0PqUWjEZ96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J8ILNyn2GFq"
      },
      "source": [
        "#### Variables temporales derivadas\n",
        "\n",
        "El momento en el que un pedido es aceptado por el repartidor tiene un impacto directo en la duración de la entrega, debido a factores como congestión urbana, patrones de demanda y disponibilidad de couriers. A partir de la variable accept_time, se derivan los siguientes componentes temporales:\n",
        "\n",
        "* Hora del día (hour)\n",
        "\n",
        "* Día de la semana (day_of_week)\n",
        "\n",
        "* ndicador de fin de semana (is_weekend),\n",
        "\n",
        "* Horas punta (is_peak_hour)-> franjas horarias con mayor congestión urbana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYIPY4Je2BHd"
      },
      "outputs": [],
      "source": [
        "# Componentes temporales clave\n",
        "df_final['hour'] = df_final['accept_time'].dt.hour\n",
        "df_final['day_of_week'] = df_final['accept_time'].dt.dayofweek\n",
        "df_final['is_weekend'] = (df_final['day_of_week'] >= 5).astype(int)\n",
        "\n",
        "# Horas punta (proxy de congestión urbana)\n",
        "df_final['is_peak_hour'] = df_final['hour'].between(7, 9) | df_final['hour'].between(17, 20)\n",
        "df_final['is_peak_hour'] = df_final['is_peak_hour'].astype(int)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjVicxW7_Cq-"
      },
      "source": [
        "#### Variables espaciales y estructurales\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Para capturar el efecto de la distancia recorrida, se calcula la distancia geográfica en kilómetros entre el punto donde el courier acepta el pedido y el punto de entrega final.\n",
        "\n",
        "Dado que las coordenadas están expresadas en latitud y longitud, se utiliza la fórmula de **Haversine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URoUykx7AA_Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371\n",
        "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
        "    dphi = np.radians(lat2 - lat1)\n",
        "    dlambda = np.radians(lon2 - lon1)\n",
        "    a = np.sin(dphi/2)**2 + np.cos(phi1)*np.cos(phi2)*np.sin(dlambda/2)**2\n",
        "    return 2 * R * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "\n",
        "df_final['distance_km'] = haversine(\n",
        "    df_final['accept_gps_lat'], df_final['accept_gps_lng'],\n",
        "    df_final['delivery_gps_lat'], df_final['delivery_gps_lng']\n",
        ")\n",
        "\n",
        "df_final['aoi_type'] = df_final['aoi_type'].astype('category')\n",
        "\n",
        "df_final['distance_km'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Validación de Rangos de Negocio (Geográficos):\")\n",
        "total_regs = len(df_final)\n",
        "\n",
        "checks = {\n",
        "    \"Distancia <= 0 km (Error GPS)\": (df_final['distance_km'] <= 0).sum(),\n",
        "    \"Distancia > 50 km (Fuera de rango urbano)\": (df_final['distance_km'] > 50).sum(),\n",
        "}\n",
        "\n",
        "for k, v in checks.items():\n",
        "    porcentaje = (v / total_regs) * 100\n",
        "    print(f\"➢ {k}: {v} registros ({porcentaje:.4f}%)\")\n",
        "\n",
        "print(f\"\\nDistancia máxima detectada: {df_final['distance_km'].max():.2f} km\")"
      ],
      "metadata": {
        "id": "CMzaz9FGQpnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Registros eliminados\n",
        "df_final2 = df_final[\n",
        "    (df_final['distance_km'] > 0.1) &\n",
        "    (df_final['distance_km'] < 50)\n",
        "].copy()\n",
        "\n",
        "print(f\"➢ Registros iniciales: {len(df_final)}\")\n",
        "print(f\"➢ Registros válidos: {len(df_final2)}\")"
      ],
      "metadata": {
        "id": "ex9AWsxLQuhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1F2k-UMAAVI"
      },
      "source": [
        "#### Variables de carga operativa\n",
        "\n",
        "Se crean variables que capturan la presión operativa del sistema en el momento de la entrega, tanto a nivel de courier como de zona geográfica.\n",
        "\n",
        "* **Carga diaria del courier** (*orders_by_courier*): número total de pedidos gestionados por un repartidor en un día determinado.\n",
        "\n",
        "* **Congestión local** (*aoi_congestion*): número de pedidos en la misma área (AOI) y franja horaria, como proxy de saturación local."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBp9OFS9AVhf"
      },
      "outputs": [],
      "source": [
        "# Carga diaria del courier\n",
        "df_final2['orders_by_courier'] = (\n",
        "    df_final2\n",
        "    .groupby(['courier_id', 'ds'])['order_id']\n",
        "    .transform('count')\n",
        ")\n",
        "\n",
        "# Congestión local por AOI y hora\n",
        "df_final2['aoi_congestion'] = (\n",
        "    df_final2\n",
        "    .groupby(['aoi_id', 'ds', 'hour'])['order_id']\n",
        "    .transform('count')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z-D9j7YAKwv"
      },
      "source": [
        "#### Preparación del dataset para modelado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HstRON2nAGte"
      },
      "outputs": [],
      "source": [
        "# Se eliminan columnas no necesarias\n",
        "cols_to_drop = [\n",
        "    'order_id', 'aoi_id',\n",
        "    'accept_time', 'delivery_time', 'ds',\n",
        "    'accept_gps_lat', 'accept_gps_lng',\n",
        "    'delivery_gps_lat', 'delivery_gps_lng'\n",
        "]\n",
        "\n",
        "df_eda = df_final2.drop(columns=cols_to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKVwVp8PlFDF"
      },
      "outputs": [],
      "source": [
        "df_eda.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDwyUUkGI7SS"
      },
      "source": [
        "### **Análisis exploratio de datos (EDA)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjiWAw4Pc8Ko"
      },
      "source": [
        "#### Análisis univariente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmHxVrWrfgIt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Visualización de la distribución\n",
        "sns.kdeplot(df_eda['delivery_duration_min'], fill=True, color=\"skyblue\", bw_adjust=0.5)\n",
        "\n",
        "# Líneas de referencia\n",
        "plt.axvline(df_eda['delivery_duration_min'].mean(), color='red', linestyle='--', label=f\"Media: {df_final['delivery_duration_min'].mean():.2f} min\")\n",
        "plt.axvline(df_eda['delivery_duration_min'].median(), color='green', linestyle='-', label=f\"Mediana: {df_final['delivery_duration_min'].median():.2f} min\")\n",
        "\n",
        "plt.title(\"Distribución de la Variable Objetivo (Tiempo de Entrega)\")\n",
        "plt.xlabel(\"Minutos\")\n",
        "plt.ylabel(\"Densidad\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOU2ib5Oe3Bq"
      },
      "source": [
        "#### Análisis bivariante y multivariante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEn3urqHVquy"
      },
      "outputs": [],
      "source": [
        "#Distancia vs tiempo\n",
        "df_zoom = df_eda[df_eda['distance_km'] <= 10]\n",
        "\n",
        "sns.regplot(\n",
        "    data=df_zoom.sample(5000, random_state=42),\n",
        "    x='distance_km',\n",
        "    y='delivery_duration_min',\n",
        "    scatter_kws={'alpha': 0.2},\n",
        "    line_kws={'color': 'red'}\n",
        ")\n",
        "plt.title(\"Relación Distancia–Tiempo (Entregas urbanas < 10 km)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diOu1sbZmMIj"
      },
      "outputs": [],
      "source": [
        "df_plot = df_eda[\n",
        "    (df_eda['distance_km'] > 0) & (df_eda['distance_km'] <= 30) &\n",
        "    (df_eda['delivery_duration_min'] > 0) & (df_eda['delivery_duration_min'] <= 300)\n",
        "].copy()\n",
        "\n",
        "df_plot['distance_category'] = pd.cut(\n",
        "    df_plot['distance_km'],\n",
        "    bins=[0, 1, 3, 7, 15, 30],\n",
        "    labels=['Muy corto', 'Corto', 'Medio', 'Largo', 'Muy largo']\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='distance_category', y='delivery_duration_min', data=df_plot, palette='Set3')\n",
        "plt.title(\"Impacto de la Distancia en el Tiempo de Entrega\")\n",
        "plt.xlabel(\"Categoría de Distancia\")\n",
        "plt.ylabel(\"Minutos de Entrega\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCLD4R90hsPX"
      },
      "outputs": [],
      "source": [
        "# Análisis de Correlación\n",
        "columnas_modelo = [\n",
        "    'delivery_duration_min',\n",
        "    'distance_km',\n",
        "    'aoi_congestion',\n",
        "    'hour',\n",
        "    'is_weekend',\n",
        "    'orders_by_courier'\n",
        "]\n",
        "\n",
        "matriz_corr = df_eda[columnas_modelo].corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    matriz_corr,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap='RdYlGn',\n",
        "    center=0\n",
        ")\n",
        "\n",
        "plt.title(\"Mapa de Correlación entre Variables Clave\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtdL54zQe-Ih"
      },
      "source": [
        "#### Análisis Temporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6kzPuiQiBFb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "sns.lineplot(\n",
        "    data=df_eda,\n",
        "    x='hour',\n",
        "    y='delivery_duration_min',\n",
        "    hue='is_weekend',\n",
        "    marker='o'\n",
        ")\n",
        "\n",
        "plt.axhline(\n",
        "    90,\n",
        "    color='red',\n",
        "    linestyle='--',\n",
        "    label='SLA (90 min)'\n",
        ")\n",
        "\n",
        "plt.xticks(range(0, 24))\n",
        "plt.title(\"Patrón Horario de Duración de Entregas\")\n",
        "plt.xlabel(\"Hora del día\")\n",
        "plt.ylabel(\"Duración promedio (min)\")\n",
        "plt.legend(title=\"Fin de semana\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTCZHfvrfxyY"
      },
      "outputs": [],
      "source": [
        "#Heatmap día-hora\n",
        "pivot = df_eda.pivot_table(\n",
        "    index='day_of_week',\n",
        "    columns='hour',\n",
        "    values='delivery_duration_min',\n",
        "    aggfunc='median'\n",
        ")\n",
        "plt.figure(figsize=(16, 6))\n",
        "\n",
        "sns.heatmap(pivot, cmap=\"YlOrRd\")\n",
        "plt.title(\"Duración mediana por día y hora\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJeV1OeNmlv-"
      },
      "source": [
        "### **Definición del problema de Machine Learning**\n",
        "\n",
        "En última milla B2C hay dos decisiones distintas en momentos distintos:\n",
        " 1. Antes de ejecutar la entrega - ¿riesgo de retraso?\n",
        " 2. Cuando el retraso ya es probable - ¿cuánto impactará?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySV_NdJQv6LL"
      },
      "source": [
        "#### **Clasificación** (Deteccion del riesgo)\n",
        "\n",
        "En la primera etapa se define un problema de clasificación binaria cuyo objetivo es identificar si una entrega superará o no el umbral de servicio establecido.\n",
        "\n",
        "El objetivo es detectar entregas con alto riesgo de incumplir el SLA para lanzar alertas tempranas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6noV_9QI_7Z"
      },
      "source": [
        "Ambos problemas están estrechamente relacionados, pero responden a objetivos distintos. Por este motivo, se construyen dos datasets específicos:\n",
        "\n",
        "* Dataset de clasificación (*df_clf*): incluye todos los pedidos y se utiliza para detectar el riesgo de retraso.\n",
        "\n",
        "* Dataset de regresión (*df_reg*): incluye únicamente los pedidos que efectivamente presentan retraso, y se utiliza para estimar su magnitud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKW7KxBM2TBJ"
      },
      "outputs": [],
      "source": [
        "# Dataset específico para clasificación (todos los pedidos)\n",
        "df_clf = df_eda.copy()\n",
        "\n",
        "# Dataset específico para regresión (solo pedidos retrasados)\n",
        "df_reg = df_eda[df_eda['target_risk_delay'] == 1].copy()\n",
        "\n",
        "print(f\"Pedidos totales (clasificación): {len(df_clf)}\")\n",
        "print(f\"Pedidos retrasados (regresión): {len(df_reg)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gi_mnQuLAb0"
      },
      "source": [
        "Antes de proceder al entrenamiento de los modelos, se realiza una validación final del dataset para asegurar su consistencia y adecuación al proceso de modelado.\n",
        "\n",
        "Se definen explícitamente las variables predictoras, diferenciando entre variables numéricas y categóricas, y se verifica que todas presenten los tipos de datos esperados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEpnD1yKk4-e"
      },
      "outputs": [],
      "source": [
        "# Definimos las features\n",
        "features_numericas = [\n",
        "    'distance_km',\n",
        "    'orders_by_courier',\n",
        "    'aoi_congestion',\n",
        "    'hour',\n",
        "    'day_of_week',\n",
        "    'is_weekend',\n",
        "    'is_peak_hour',\n",
        "    'courier_mean_delay',\n",
        "    'courier_volume',\n",
        "    'courier_sla_rate',\n",
        "\n",
        "]\n",
        "\n",
        "features_categoricas = ['aoi_type', 'region_id']\n",
        "\n",
        "features = features_numericas + features_categoricas\n",
        "\n",
        "print(\"Features finales numericas:\", features_numericas)\n",
        "print(\"Features finales categóricas:\", features_categoricas)\n",
        "print(\"\\nTipos de datos:\")\n",
        "print(df_eda[features_numericas].dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uboPe2zM6IPV"
      },
      "outputs": [],
      "source": [
        "# Columnas clave para modelado\n",
        "\n",
        "X = df_eda[features]\n",
        "y_class = df_eda['target_risk_delay']\n",
        "cols_check = features + ['target_risk_delay', 'target_delay_min']\n",
        "\n",
        "print(\"Nulos por columna:\")\n",
        "print(df_eda[cols_check].isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAgHhid96MiZ"
      },
      "outputs": [],
      "source": [
        "print(\"\\nRangos de variables numéricas:\")\n",
        "display(\n",
        "    df_eda[\n",
        "        ['delivery_duration_min', 'distance_km',\n",
        "         'aoi_congestion', 'orders_by_courier']\n",
        "    ].describe().round(2)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV2gDZii6PG7"
      },
      "outputs": [],
      "source": [
        "print(\"\\nDistribución del target de clasificación (%):\")\n",
        "display(\n",
        "    df_eda['target_risk_delay']\n",
        "    .value_counts(normalize=True)\n",
        "    .mul(100)\n",
        "    .round(2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqH178VV6S6A"
      },
      "outputs": [],
      "source": [
        "print(\"\\nDistribución del target de regresión (solo retrasos):\")\n",
        "display(\n",
        "    df_eda[df_eda['target_risk_delay'] == 1]\n",
        "    ['target_delay_min']\n",
        "    .describe()\n",
        "    .round(2)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c6SmrMtrWyW"
      },
      "source": [
        "### **Pipeline de Procesamiento y Entrenameinto**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se0qFkTu24iQ"
      },
      "source": [
        "#### Separación Train/Test y pipeline de preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQqLtkDT3oWO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_eda[features]\n",
        "y_class = df_eda['target_risk_delay']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul5d8hP3NlzX"
      },
      "source": [
        "Se define un preprocesador que:\n",
        "\n",
        " * Escala las variables numéricas con StandardScaler\n",
        "\n",
        " * Codifica variables categóricas con OneHotEncoder ignorando categorías desconocidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YT34P43v7xbO"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), features_numericas),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), ['aoi_type'])\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pipeline final\n",
        "final_pipeline_clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', df_clf)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck3Gq2Ez3Jbp"
      },
      "source": [
        "#### **Entrenamiento y Validación de modelos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiwM1UVQNyjp"
      },
      "source": [
        "Para acelerar la experimentación, se submuestrea un conjunto representativo de 300k registros del entrenamiento:\n",
        "\n",
        "* Clasificación: Logistic Regression, Random Forest, Gradient Boosting\n",
        "\n",
        "* Regresión: Gradient Boosting Regressor, Random Forest Regressor\n",
        "\n",
        "Se evalúan métricas relevantes:\n",
        "\n",
        "* Clasificación → Accuracy, Precision, Recall, F1, ROC-AUC\n",
        "\n",
        "* Regresión → MAE, RMSE, R²\n",
        "\n",
        "Esta etapa permite comparar modelos rápidamente y decidir cuál entrenar con el dataset completo posteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrLJUAdg3JpQ"
      },
      "source": [
        "#### Comparación Inicial entre modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iGZTN2xRpDc"
      },
      "source": [
        "Se han seleccionado tres arquitecturas con naturalezas matemáticas distintas para cubrir el espectro de aprendizaje:\n",
        "\n",
        "Logistic Regression (Baseline): Un modelo lineal que permite evaluar la separabilidad simple de los datos. Sirve como referencia de complejidad mínima.\n",
        "\n",
        "XGBoost (Extreme Gradient Boosting): Algoritmo basado en árboles de decisión con crecimiento por niveles (level-wise). Es el estándar de la industria por su capacidad de regularización y manejo de relaciones no lineales.\n",
        "\n",
        "LightGBM (Light Gradient Boosting Machine): Optimizado para grandes volúmenes de datos mediante el crecimiento por hojas (leaf-wise). Su eficiencia en memoria y velocidad lo hacen el candidato ideal para despliegues en tiempo real en logística."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOuWDY_i3lrZ"
      },
      "source": [
        "*MODELO DE CLASIFICACIÓN*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi9HKWYP3Ida"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import time\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_6IcApt3P9e"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "\n",
        "pipelines = {\n",
        "    'LogisticRegression': Pipeline([\n",
        "        ('preprocess', preprocessor),\n",
        "        ('model', LogisticRegression(\n",
        "            max_iter=1000,\n",
        "            class_weight='balanced',\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ]),\n",
        "    'XGBoost': Pipeline([\n",
        "        ('preprocess', preprocessor),\n",
        "        ('model', XGBClassifier(\n",
        "            n_estimators=200,\n",
        "            max_depth=6,\n",
        "            scale_pos_weight=ratio,\n",
        "            learning_rate=0.1,\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ]),\n",
        "    'LightGBM': Pipeline([\n",
        "        ('preprocess', preprocessor),\n",
        "        ('model', LGBMClassifier(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.05,\n",
        "            scale_pos_weight=ratio,\n",
        "            n_jobs=-1,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwBn67eVQ-Yi"
      },
      "source": [
        "Dada la magnitud del dataset original (approx 2.2 millones), el entrenamiento iterativo de múltiples modelos incurre en un alto coste computacional. Se ha optado por un Submuestreo Estratificado de $300,000$ observaciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkaLvNup1-9f"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Submuestreo solo para comaprar los modelos (muestra representativa)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sampleamos 300k registros manteniendo proporción de clases\n",
        "X_sample, _, y_sample, _ = train_test_split(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    train_size=300_000,\n",
        "    stratify=y_train,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah4g6x_YRsi_"
      },
      "source": [
        "#### Métricas de Evaluación y Optimización del Negocio\n",
        "El éxito del modelo no se mide solo por su capacidad de acierto general (Accuracy), sino por su eficiencia operativa.Coste de Error: En la operativa de LaDe, un Falso Positivo (predecir un retraso que no ocurre) implica un coste logístico innecesario.Métrica Primaria ($F_{0.5}$-Score): Se utiliza la métrica $F_{\\beta}$ con un valor de $\\beta = 0.5$.$$F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{(\\beta^2 \\cdot \\text{precision}) + \\text{recall}}$$\n",
        "\n",
        "\n",
        "Al fijar $\\beta = 0.5$, se otorga mayor peso relativo a la Precisión que al Recall, penalizando más severamente las falsas alarmas que las omisiones, sin descuidar la detección de retrasos críticos (SLA)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chhDGpwG3SuH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, fbeta_score\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, pipe in pipelines.items():\n",
        "    print(f\"Entrenando {name}...\")\n",
        "    start = time.time()\n",
        "\n",
        "    # Entrenamos con la muestra de 300k\n",
        "    pipe.fit(X_sample, y_sample)\n",
        "\n",
        "    # Predicciones\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    y_proba = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    end_time = round((time.time() - start) / 60, 2)\n",
        "\n",
        "    # Calculamos F-beta (beta=0.5) para priorizar Precisión sobre Recall\n",
        "    f05 = fbeta_score(y_test, y_pred, beta=0.5)\n",
        "\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Time (min)': end_time,\n",
        "        'AUC-ROC': roc_auc_score(y_test, y_proba),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred),\n",
        "        'F0.5-Score (Prec-focused)': f05\n",
        "    })\n",
        "\n",
        "# Creamos el DataFrame y ordenamos por F0.5 para ver cuál es más \"rentable\"\n",
        "df_results_cls = pd.DataFrame(results).sort_values(by='F0.5-Score (Prec-focused)', ascending=False)\n",
        "\n",
        "print(\"\\n--- RESULTADOS COMPARATIVOS ---\")\n",
        "display(df_results_cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFClrBIcUeME"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import numpy as np\n",
        "\n",
        "# Obtenemos las probabilidades del mejor modelo\n",
        "y_scores = pipelines['LightGBM'].predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculamos precisiones y recalls\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Creamos un DataFrame para analizar los umbrales\n",
        "df_thresholds = pd.DataFrame({\n",
        "    'threshold': thresholds,\n",
        "    'precision': precisions[:-1],\n",
        "    'recall': recalls[:-1]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBNdwwxiUhjW"
      },
      "outputs": [],
      "source": [
        "# Buscamos el umbral que nos de al menos un 64% de precisión\n",
        "objetivo_precision = 0.64\n",
        "umbral_ajustado = df_thresholds[df_thresholds['precision'] >= objetivo_precision]['threshold'].min()\n",
        "\n",
        "print(f\"Para obtener una precisión del {objetivo_precision*100}%, el umbral debe ser: {umbral_ajustado:.2f}\")\n",
        "\n",
        "# Ver qué recall nos queda con ese umbral\n",
        "recall_resultante = df_thresholds[df_thresholds['threshold'] >= umbral_ajustado]['recall'].iloc[0]\n",
        "print(f\"Con este umbral, capturarás el {recall_resultante*100:.21f}% de los retrasos totales.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LsLUAfcUlWL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(thresholds, precisions[:-1], 'b--', label='Precisión (Evitar Falsas Alarmas)', lw=2)\n",
        "plt.plot(thresholds, recalls[:-1], 'g-', label='Recall (Detectar Retrasos Reales)', lw=2)\n",
        "plt.axvline(x=umbral_ajustado, color='red', linestyle=':', label=f'Umbral Sugerido ({umbral_ajustado:.2f})')\n",
        "plt.xlabel('Umbral de Probabilidad')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Ajuste de Umbral para Maximizar Precisión Operativa')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOR9avMJJeIg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import make_scorer, fbeta_score\n",
        "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
        "import time\n",
        "\n",
        "# Scorer F0.5\n",
        "f05_scorer = make_scorer(fbeta_score, beta=0.5)\n",
        "\n",
        "# Split para Early Stopping (importante para validar cada iteración)\n",
        "X_train_tune, X_val_tune, y_train_tune, y_val_tune = train_test_split(\n",
        "    X_sample, y_sample,\n",
        "    test_size=0.2,\n",
        "    stratify=y_sample,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Parámetros\n",
        "param_dist_lgbm = {\n",
        "    'n_estimators': [500, 1000, 1500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'num_leaves': [31, 63, 127],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'min_child_samples': [20, 50, 100],\n",
        "    'reg_alpha': [0, 0.1, 0.5],\n",
        "    'reg_lambda': [0, 0.1, 0.5],\n",
        "    'scale_pos_weight': [ratio]\n",
        "}\n",
        "\n",
        "# Configuramos el modelo base\n",
        "lgbm_base = LGBMClassifier(random_state=42, n_jobs=-1, verbosity=-1)\n",
        "\n",
        "random_search_lgbm = RandomizedSearchCV(\n",
        "    estimator=lgbm_base,\n",
        "    param_distributions=param_dist_lgbm,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    scoring=f05_scorer,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 5Ejecución con FIT modificado\n",
        "print(\"Iniciando búsqueda con Early Stopping...\")\n",
        "start = time.time()\n",
        "\n",
        "random_search_lgbm.fit(\n",
        "    X_train_tune, y_train_tune,\n",
        "    eval_set=[(X_val_tune, y_val_tune)],\n",
        "    eval_metric='binary_logloss',\n",
        "    callbacks=[\n",
        "        early_stopping(stopping_rounds=50),\n",
        "        log_evaluation(period=0) # Para que no ensucie la consola con cada árbol\n",
        "    ]\n",
        ")\n",
        "\n",
        "duration = (time.time() - start) / 60\n",
        "print(f\"\\n Tuning completado en {duration:.2f} minutos\")\n",
        "print(f\"Mejores parámetros: {random_search_lgbm.best_params_}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZkcQ3Ip3pXr"
      },
      "source": [
        "*MODELO DE REGRESIÓN*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6JHLHIj3s6X"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Nos quedamos solo con pedidos retrasados\n",
        "X_reg = df_reg[features]\n",
        "y_reg = df_reg['target_delay_min']\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg,\n",
        "    y_reg,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8HrCLl07160"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Submuestreo del conjunto de entrenamiento\n",
        "X_train_reg_sample, _, y_train_reg_sample, _ = train_test_split(\n",
        "    X_train_reg,\n",
        "    y_train_reg,\n",
        "    train_size=300_000,\n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se seleccionan algoritmos de Boosting (LightGBM y XGBoost) para la fase de regresión dada su superioridad previa en la clasificación. El objetivo es minimizar el MAE, alineándose con la necesidad de negocio de proporcionar una estimación de tiempo realista al cliente final, siendo esta métrica menos sensible a retrasos extremos atípicos que el RMSE.\""
      ],
      "metadata": {
        "id": "I7_BwyLk_4ki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnAax1DH3wIj"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "pipelines_reg = {\n",
        "    'LightGBM_Reg': Pipeline([\n",
        "        ('preprocess', preprocessor),\n",
        "        ('model', LGBMRegressor(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.05,\n",
        "            num_leaves=63,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ))\n",
        "    ]),\n",
        "    'XGBoost_Reg': Pipeline([\n",
        "        ('preprocess', preprocessor),\n",
        "        ('model', XGBRegressor(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=6,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ))\n",
        "    ])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABI3-6zy4J7W"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "results_reg = []\n",
        "\n",
        "for name, pipe in pipelines_reg.items():\n",
        "    print(f\"Executing Regression Benchmark: {name}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Entrenamiento sobre la muestra de registros con retraso real\n",
        "    pipe.fit(X_train_reg_sample, y_train_reg_sample)\n",
        "\n",
        "    # Predicción sobre el set de test de regresión\n",
        "    y_pred = pipe.predict(X_test_reg)\n",
        "\n",
        "    # Cálculo de métricas\n",
        "    mae = mean_absolute_error(y_test_reg, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))\n",
        "    r2 = r2_score(y_test_reg, y_pred)\n",
        "\n",
        "    elapsed_time = (time.time() - start_time) / 60\n",
        "\n",
        "    results_reg.append({\n",
        "        'Model': name,\n",
        "        'Time (min)': round(elapsed_time, 2),\n",
        "        'MAE (Minutos)': round(mae, 2),\n",
        "        'RMSE': round(rmse, 2),\n",
        "        'R2 Score': round(r2, 4)\n",
        "    })\n",
        "\n",
        "# Visualización de resultados ordenada por MAE\n",
        "df_results_reg = pd.DataFrame(results_reg).sort_values('MAE (Minutos)')\n",
        "\n",
        "# Añadimos una columna para entender el error relativo\n",
        "mean_delay = y_test_reg.mean()\n",
        "df_results_reg['Error Relativo %'] = round((df_results_reg['MAE (Minutos)'] / mean_delay) * 100, 2)\n",
        "\n",
        "display(df_results_reg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhZcrsVagde8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
        "import time\n",
        "\n",
        "# Split para validación del Early Stopping\n",
        "# Usamos el set de regresión que ya tenías filtrado\n",
        "X_train_reg_tune, X_val_reg_tune, y_train_reg_tune, y_val_reg_tune = train_test_split(\n",
        "    X_train_reg_sample, y_train_reg_sample,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Definir espacio de búsqueda\n",
        "param_dist_lgbm_reg = {\n",
        "    'model__n_estimators': [500, 1000, 1500],\n",
        "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
        "    'model__num_leaves': [31, 63, 127],\n",
        "    'model__max_depth': [-1, 10, 20],\n",
        "    'model__min_child_samples': [20, 50, 100],\n",
        "    'model__reg_alpha': [0, 0.1, 0.5],\n",
        "    'model__reg_lambda': [0, 0.1, 0.5]\n",
        "}\n",
        "\n",
        "# Configurar el RandomizedSearchCV\n",
        "X_val_reg_prep = pipelines_reg['LightGBM_Reg'].named_steps['preprocess'].transform(X_val_reg_tune)\n",
        "\n",
        "random_search_lgbm_reg = RandomizedSearchCV(\n",
        "    pipelines_reg['LightGBM_Reg'],\n",
        "    param_distributions=param_dist_lgbm_reg,\n",
        "    n_iter=15,\n",
        "    cv=3,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Ejecución del Fit con lógica de early_stopping\n",
        "print(\"Buscando mejores parámetros de regresión con Early Stopping...\")\n",
        "start = time.time()\n",
        "\n",
        "random_search_lgbm_reg.fit(\n",
        "    X_train_reg_tune, y_train_reg_tune,\n",
        "    model__eval_set=[(X_val_reg_prep, y_val_reg_tune)],\n",
        "    model__eval_metric='mae',\n",
        "    model__callbacks=[\n",
        "        early_stopping(stopping_rounds=50),\n",
        "        log_evaluation(period=0)\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"\\n Tuning de regresión completado en {(time.time() - start)/60:.2f} min\")\n",
        "print(f\"Mejores parámetros: {random_search_lgbm_reg.best_params_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci0qB3xSPTM8"
      },
      "source": [
        "### **Entrenamiento sobre todo el Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### *Modelo de Clasificación*"
      ],
      "metadata": {
        "id": "7iw3irFR3Dwm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujyHQdDyu_nW"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Configuración con los mejores parámetros del último Tuning\n",
        "final_model_lgbm = LGBMClassifier(\n",
        "    n_estimators=1500,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=127,\n",
        "    max_depth=20,\n",
        "    min_child_samples=20,\n",
        "    reg_alpha=0.5,\n",
        "    reg_lambda=0.1,\n",
        "    scale_pos_weight=1.0536138199676675,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Pipeline definitivo\n",
        "final_pipeline_clf = Pipeline(steps=[\n",
        "    ('preprocess', preprocessor),\n",
        "    ('model', final_model_lgbm)\n",
        "])\n",
        "\n",
        "# Entrenamiento masivo\n",
        "print(\"Iniciando entrenamiento final del Clasificador...\")\n",
        "final_pipeline_clf.fit(X_train, y_train)\n",
        "print(\"Clasificador entrenado con éxito\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Obtenemos probabilidades con el pipeline que acabamos de entrenar\n",
        "y_probs = final_pipeline_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Aplicamos el umbral qcalculado para el 64% de precisión\n",
        "umbral_objetivo = 0.34\n",
        "y_pred_final = (y_probs >= umbral_objetivo).astype(int)\n",
        "\n",
        "# Informe de rendimiento\n",
        "print(f\"\\n--- REPORTE DE RENDIMIENTO FINAL (Umbral {umbral_objetivo}) ---\")\n",
        "print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "# Matriz de Confusión\n",
        "cm = confusion_matrix(y_test, y_pred_final)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['A tiempo', 'Retraso > 100min'])\n",
        "disp.plot(cmap='Blues', ax=ax)\n",
        "plt.title(f'Matriz de Confusión Final - Umbral {umbral_objetivo}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TL1agoUeh3sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mediante la optimización del umbral de decisión a 0.34, el modelo de clasificación basado en LightGBM ha alcanzado un equilibrio óptimo entre sensibilidad y precisión. El sistema demuestra una tasa de recuperación (Recall) del 88%, asegurando que asegura que 2 de cada 3 alertas de alto riesgo son certeras. Asimismo, el modelo presenta una precisión del 64%, lo que dota a las alertas de una alta fiabilidad operativa: 2 de cada 3 alarmas emitidas corresponden a un retraso real, permitiendo una gestión de riesgos proactiva con una tasa de falsos positivos plenamente asumible por la cadena de suministro."
      ],
      "metadata": {
        "id": "EPcL-ndO8NGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretación de \"Riesgo de Retraso\" (Clase 1):**\n",
        "\n",
        "Recall del 88%: Este resultado es masivo para la operativa. Significa que de cada 100 pedidos que realmente se van a retrasar e incumplir el SLA, el modelo \"caza\" a 88. Solo se le escapan 12 (representados por los 24,965 falsos negativos de la esquina inferior izquierda). Es una red de seguridad bastante eficiente.\n",
        "\n",
        "Precisión del 67%: Se superó el objetivo inicial de fiabilidad. De cada 100 veces que el modelo hace saltar la alarma de \"Alto Riesgo\", 67 son aciertos reales. Esto otorga al sistema una credibilidad suficiente para que los gestores de tráfico confíen en las alertas y tomen medidas proactivas.\n",
        "\n",
        "**Interpretación de \"Sin Riesgo de Retraso\" (Clase 0):**\n",
        "\n",
        "Precisión del 84%: Cuando el modelo clasifica una operación como de \"Bajo Riesgo\" (llegará a tiempo), acierta el 84% de las veces. Esto ofrece una garantía de tranquilidad muy alta para el flujo normal de trabajo, permitiendo poner el foco solo donde realmente hace falta.\n",
        "\n",
        "**Análisis de Falsos Positivos (91,105):**\n",
        "\n",
        "Existe un volumen de pedidos que el modelo marcó como riesgo pero que finalmente llegaron a tiempo. En el contexto logístico de última milla, este error es el \"menor de los males\". Es preferible estar sobre-alertado y supervisar un proceso que finalmente resulta exitoso, que dejar pasar un retraso crítico sin previo aviso. Estos casos representan oportunidades de mejora donde, aunque no hubo retraso, las condiciones de la entrega eran lo suficientemente inestables como para activar la sospecha del algoritmo."
      ],
      "metadata": {
        "id": "Al7h_Gta602y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyQgChFqVvYx"
      },
      "source": [
        "#### *Modelo de Regresión*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Configuración con los MEJORES parámetros encontrados en el Tuning\n",
        "final_model_reg = LGBMRegressor(\n",
        "    n_estimators=1500,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=127,\n",
        "    max_depth=20,\n",
        "    min_child_samples=20,\n",
        "    reg_alpha=0.5,\n",
        "    reg_lambda=0.1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Pipeline de regresión definitivo\n",
        "final_pipeline_reg = Pipeline(steps=[\n",
        "    ('preprocess', preprocessor),\n",
        "    ('model', final_model_reg)\n",
        "])\n",
        "\n",
        "# Entrenamiento con todos los datos de regresión (X_reg, y_reg)\n",
        "print(f\"Iniciando entrenamiento final del Regresor con {len(X_reg)} registros de retraso...\")\n",
        "final_pipeline_reg.fit(X_reg, y_reg)\n",
        "print(\"Regresor entrenado con éxito\")"
      ],
      "metadata": {
        "id": "uw0Yin5Q3krp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Predicciones sobre el set de test de regresión\n",
        "y_pred_reg = final_pipeline_reg.predict(X_test_reg)\n",
        "\n",
        "# Cálculo de métricas finales\n",
        "mae_final = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "rmse_final = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
        "r2_final = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(\"\\n--- RENDIMIENTO FINAL DEL MODELO DE REGRESIÓN ---\")\n",
        "print(f\"MAE: {mae_final:.2f} min (Error promedio por pedido)\")\n",
        "print(f\"RMSE: {rmse_final:.2f}\")\n",
        "print(f\"R2 Score: {r2_final:.4f}\")\n",
        "\n",
        "# Visualización de error: Predicción vs Realidad\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_reg, y_pred_reg, alpha=0.3, color='orange')\n",
        "plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'k--', lw=2)\n",
        "plt.xlabel('Retraso Real (min)')\n",
        "plt.ylabel('Retraso Predicho (min)')\n",
        "plt.title('Dispersión de la Predicción: Real vs. Modelo')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YnWdvUsR39CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez identificado el riesgo mediante el modelo de clasificación, el sistema de regresión estima el impacto temporal con una robustez estadística notable para el sector logístico. El modelo ha alcanzado un R² de 0.416, logrando explicar más del 41% de la variabilidad de los tiempos de retraso. Con un Error Absoluto Medio (MAE) de 50.63 minutos, el sistema proporciona una estimación precisa que sirve como base para la toma de decisiones operativas"
      ],
      "metadata": {
        "id": "i70Elrmw80mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Gráfico de Dispersión*\n",
        "\n",
        "El \"Efecto Embudo\" (Heterocedasticidad): Fíjate que para retrasos reales cortos (0-100 min), los puntos naranjas están más cerca de la línea negra. A medida que el retraso real aumenta (300-400 min), los puntos se dispersan más. Esto es normal: es mucho más fácil predecir un retraso común que uno catastrófico"
      ],
      "metadata": {
        "id": "3B31jxqO-1-Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7LQaEKjXPxP"
      },
      "source": [
        "EVALUACION MODELOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09tgv4vM8aXd"
      },
      "source": [
        "### 10. Interpretación y conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Importance"
      ],
      "metadata": {
        "id": "AZ-w03Pj4GmW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvUy3as08i7D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Recuperar el transformador del pipeline\n",
        "preprocessor = final_pipeline_reg.named_steps['preprocess']\n",
        "\n",
        "# Obtener nombres de columnas categóricas (tras One-Hot Encoding)\n",
        "try:\n",
        "    cat_features_transformed = list(preprocessor.named_transformers_['cat'].get_feature_names_out(features_categoricas))\n",
        "    feature_names = features_numericas + cat_features_transformed\n",
        "except:\n",
        "    # Si falla por los nombres, intentamos obtenerlo de forma genérica\n",
        "    feature_names = features_numericas + list(preprocessor.named_transformers_['cat'].get_feature_names_out())\n",
        "\n",
        "# Extraer las importancias del modelo\n",
        "importances = final_pipeline_reg.named_steps['model'].feature_importances_\n",
        "\n",
        "# Crear el DataFrame\n",
        "df_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Graficar el Top 15\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.barplot(x='Importance', y='Feature', data=df_importance.head(15), palette='magma')\n",
        "\n",
        "plt.title('Análisis de Importancia de Variables (Gini Importance)\\nModelo de Regresión Final', fontsize=14)\n",
        "plt.xlabel('Importancia Relativa', fontsize=12)\n",
        "plt.ylabel('Variables Predictoras', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* El factor distancia (distance_km): Es la variable más importante. Esto valida el modelo: a mayor distancia, mayor es la acumulación de incertidumbre y probabilidad de un retraso largo. Es el motor principal de la predicción de minutos.\n",
        "\n",
        "* Carga de trabajo por repartidor (orders_by_courier): Esta es una variable operativa crítica. Indica que el volumen de pedidos asignado a un solo repartidor impacta directamente en la magnitud del retraso. Si un repartidor va sobrecargado, el retraso no es de 10 minutos, es de 100 o más.\n",
        "\n",
        "* Temporalidad y Congestión (hour, aoi_congestion): La hora del día y la congestión del área de interés (AOI) aparecen en el Top 6. Esto sugiere que el modelo ha aprendido los patrones de tráfico y horas punta de la ciudad.\n",
        "\n",
        "* Histórico del transportista (courier_mean_delay): El modelo está penalizando o premiando basándose en el comportamiento pasado de los repartidores. Es una variable de \"reputación\" que ayuda a ajustar los minutos finales."
      ],
      "metadata": {
        "id": "rLTC8t7A_9IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 1. Guardar el Pipeline de Clasificación (Riesgo)\n",
        "# Este archivo contiene el preprocesador y el modelo con el umbral optimizado\n",
        "joblib.dump(final_pipeline_clf, 'pipeline_clasificacion_lade.joblib')\n",
        "\n",
        "# 2. Guardar el Pipeline de Regresión (Minutos)\n",
        "# Este archivo contiene el preprocesador y el modelo que estima el MAE de 50 min\n",
        "joblib.dump(final_pipeline_reg, 'pipeline_regresion_lade.joblib')\n",
        "\n",
        "print(\"Modelos guardados con éxito en formato .joblib\")"
      ],
      "metadata": {
        "id": "Mx4gYqAp_Ye7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez finalizado el entrenamiento masivo con 2.2 millones de registros, es fundamental garantizar la persistencia de los modelos para su posterior despliegue en un entorno de producción. Para ello, utilizamos la serialización de modelos mediante joblib.\n",
        "\n",
        "La serialización es el proceso de transformar la estructura del objeto de Python (en este caso, nuestros Pipelines que contienen tanto el preprocesamiento como el modelo LightGBM entrenado) en un formato de archivo binario (.joblib). Esto permite:\n",
        "\n",
        "* Reutilización: Cargar el modelo en milisegundos sin necesidad de reentrenar.\n",
        "\n",
        "* Integridad: Asegurar que el preprocesamiento de los nuevos datos sea idéntico al utilizado durante el entrenamiento."
      ],
      "metadata": {
        "id": "7IWawnnt_tWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque el sistema actual proporciona una base sólida para la gestión de riesgos, existen líneas de investigación que podrían elevar el rendimiento del modelo en futuras iteraciones:\n",
        "\n",
        "* Enriquecimiento de Variables (Feature Engineering): La inclusión de datos meteorológicos en tiempo real y eventos locales (conciertos, huelgas, cierres de vías) podría explicar parte de la varianza que actualmente el modelo no captura, mejorando potencialmente el $R^2$ del modelo de regresión.\n",
        "\n",
        "* Modelos de Series Temporales: Incorporar el componente de estacionalidad mediante técnicas de Deep Learning (como redes LSTM) podría ayudar a predecir retrasos en picos de demanda extrema como el 'Black Friday' o periodos festivos."
      ],
      "metadata": {
        "id": "0pYEigwiAbhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pk60ifB6HDcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos las columnas exactas que el modelo espera (las de tu X_train)\n",
        "columnas_modelo = X_train.columns.tolist()\n",
        "\n",
        "# Creamos el dataset codificado\n",
        "df_para_muestreo = pd.get_dummies(df_eda)\n",
        "\n",
        "# Tomamos la muestra y forzamos las 126 columnas\n",
        "# Esto crea las columnas que falten (con 0) y elimina las que sobren\n",
        "muestras_gradio = df_para_muestreo.reindex(columns=columnas_modelo, fill_value=0).sample(20, random_state=42)\n",
        "\n",
        "# Guardamos en carpeta de Drive\n",
        "ruta_proyecto = \"/content/drive/MyDrive/GRADIO - LastMilePulse/\"\n",
        "muestras_gradio.to_csv(ruta_proyecto + 'ejemplos_para_gradio.csv', index=False)\n",
        "\n",
        "print(f\"Archivo guardado con éxito.\")\n",
        "print(f\"Total columnas: {muestras_gradio.shape[1]} \")"
      ],
      "metadata": {
        "id": "V31YeG15M5JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Definimos la ruta\n",
        "ruta= '/content/drive/MyDrive/GRADIO - LastMilePulse/'\n",
        "\n",
        "# Intentamos guardar los tres archivos en la carpeta\n",
        "import os\n",
        "if os.path.exists(ruta):\n",
        "    muestras_gradio.to_csv(ruta + 'ejemplos_para_gradio.csv', index=False)\n",
        "\n",
        "    import joblib\n",
        "    joblib.dump(final_pipeline_clf, ruta + 'pipeline_clasificacion_lade.joblib')\n",
        "    joblib.dump(final_pipeline_reg, ruta + 'pipeline_regresion_lade.joblib')\n",
        "    print(f\"¡CONSEGUIDO! Archivos guardados en: {ruta}\")\n",
        "else:\n",
        "    print(\"La carpeta no se encuentra con ese nombre. Revisa espacios o guiones.\")"
      ],
      "metadata": {
        "id": "fhkGcr_GC1x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargamos muestra de datos aleatoria para utilizar en la herramienta\n",
        "\n",
        "# Definimos las columnas exactas que mencionaste\n",
        "columnas_herramienta = [\n",
        "    'order_id','region_id', 'city', 'courier_id', 'lng', 'lat', 'aoi_type',\n",
        "    'accept_gps_time', 'delivery_gps_time', 'delivery_duration_min',\n",
        "    'hour', 'day_of_week', 'is_weekend', 'is_peak_hour',\n",
        "    'distance_km', 'orders_by_courier', 'aoi_congestion',\n",
        "    'target_risk_delay', 'target_delay_min',\n",
        "    'courier_mean_delay', 'courier_volume', 'courier_sla_rate'\n",
        "]\n",
        "\n",
        "# Tomamos una muestra aleatoria (50 registros)\n",
        "df_ejemplos = df_final2[columnas_herramienta].sample(n=50, random_state=42)\n",
        "\n",
        "# Guardamos el archivo CSV\n",
        "df_ejemplos.to_csv(f'{ruta}ejemplos_LastMilePulse.csv', index=False)\n",
        "\n",
        "print(\"Archivo 'ejemplos_LastMilePulse.csv' generado con éxito.\")"
      ],
      "metadata": {
        "id": "Zd_P2tPvR3Je"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}